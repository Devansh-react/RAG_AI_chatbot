# ğŸ” RAGAgent - Hybrid RAG + Web Search AI Chatbot

RAGAgent is an intelligent hybrid chatbot system that combines **Retrieval-Augmented Generation (RAG)** and **real-time web search** capabilities to provide precise, up-to-date, and context-aware responses. It uses **Google Gemini** as the underlying LLM and classifies queries to route them through the optimal information pipeline.



---

## ğŸ§  System Overview

The application handles queries by routing them based on **intent classification** into three paths:

1. **RAG Lookup**: If query is informational or previously known, it uses vector DB retrieval.
2. **Web Search**: If it's real-time (e.g., current events), it uses a DuckDuckGo search tool.
3. **LLM Answering**: If neither RAG nor web search answers it well, Gemini LLM generates a response.

---

## ğŸ“ Project Structure

```bash
RAGAGENT/
â”‚
â”œâ”€â”€ Agents/                  # LLM-based agents (retrievers, checkers)
â”œâ”€â”€ Tools/                   # Custom tools
â”‚   â”œâ”€â”€ rag_tools.py
â”‚   â””â”€â”€ webSearch_tool.py    # DuckDuckGo web search tool
â”œâ”€â”€ classifiers/             # Intent classifiers
â”œâ”€â”€ database/                # RAG DB (FAISS or similar)
â”œâ”€â”€ graph/                   # LangGraph workflow configuration
â”œâ”€â”€ schema/                  # Pydantic schemas (e.g., State)
â”‚   â””â”€â”€ Models.py
â”œâ”€â”€ utilities/               # Helpers, Gemini init, etc.
â”œâ”€â”€ .env                     # Environment variables (API keys, etc.)
â”œâ”€â”€ app.py                   # FastAPI app for serving frontend/backend
â”œâ”€â”€ main.py                  # Entry point for initializing LangGraph
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ image.png                # System architecture diagram
â””â”€â”€ FOLDER_STRUCT.txt        # Folder layout (optional docs)
```

---

## ğŸ› ï¸ Features

- ğŸ” **Query Classification** using intent detection
- ğŸ“š **RAG Integration** via FAISS vector DB
- ğŸŒ **Real-time Web Search** using DuckDuckGo API
- ğŸ¤– **Gemini LLM** for fallback generation
- ğŸ§ª Modular tools and graph nodes for LangGraph
- ğŸš€ Built with **FastAPI** for scalability

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/RAGAgent.git
cd RAGAgent
```

### 2. Install Requirements

```bash
pip install -r requirements.txt
```

### 3. Setup Environment Variables

Create a `.env` file with your Gemini API key:

```env
GEMINI_API_KEY=your_google_gemini_api_key
```

### 4. Run the App

```bash
uvicorn app:app --reload
```

---

## ğŸ”§ Tools Used

| Tool            | Purpose                      |
|-----------------|------------------------------|
| **LangChain / LangGraph** | Workflow and LLM orchestration |
| **Gemini API**  | Large Language Model         |
| **DuckDuckGo API** | Real-time web search         |
| **FAISS**       | Vector similarity search     |
| **FastAPI**     | Backend framework            |
| **Pydantic**    | Input/output validation      |

---

## ğŸ“Œ Query Flow

```
User Message
   â†“
Classifier (Intent)
   â”œâ”€â†’ RAG Lookup (Vector DB) â”€â†’ Checker â”€â†’ LLM Answer or RAG Answer
   â””â”€â†’ Web Search â”€â†’ Gemini LLM â”€â†’ Final Answer
```

Diagram:  
![Query Flow](./image.png)

---

## ğŸ“ˆ Future Improvements

- Add memory for context retention
- Integrate LangSmith for observability
- UI frontend for chat interactions
- Add Redis for caching results

---

## ğŸ“„ License

This project is licensed under the MIT License.